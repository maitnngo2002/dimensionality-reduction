{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pf2xnSJH9wQJ"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.layers import Input, InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
        "from tensorflow.keras.layers import AveragePooling2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.linalg import eigh\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pW8Ge0FD-rzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dataset\n"
      ],
      "metadata": {
        "id": "c_geamXo-slr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scoJVRh3-1z0",
        "outputId": "f7971ae4-79e7-442e-812c-805e41cd6a50"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing dataset"
      ],
      "metadata": {
        "id": "8aIudaPO_C3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization\n",
        "\n",
        "X_train = X_train / 255.\n",
        "X_test = X_test / 225.\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)"
      ],
      "metadata": {
        "id": "QBnRw_a1-9Fr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LddgxPAG_RzB",
        "outputId": "8422a552-f305-40c8-b952-a287b6b7f0b7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784) (60000,) (10000, 784) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA"
      ],
      "metadata": {
        "id": "0_2Ru8kZ_WUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# may not need to use StandardScaler. Instead, could just subtract the average from each data point\n",
        "\n",
        "standardized_scalar = StandardScaler()\n",
        "\n",
        "standardized_data = standardized_scalar.fit_transform(X_train)\n",
        "standardized_data.shape\n",
        "\n",
        "standardized_data_test = standardized_scalar.transform(X_test)\n",
        "standardized_data_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahHAb-HV_Uru",
        "outputId": "2cacdbc8-ff92-4efe-9c32-860286834bc0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# covariance matrix is X_transpose times X\n",
        "cov_matrix = np.matmul(standardized_data.T, standardized_data)\n",
        "\n",
        "\n",
        "conv_matrix_test = np.matmul(standardized_data_test.T, standardized_data_test)\n",
        "\n",
        "print(cov_matrix.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ssmz2qVH_3DQ",
        "outputId": "e2633a8b-1fd3-4c3e-b9be-4280ec5bd56a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate eigenvalues and eigenvectors for train set\n",
        "\n",
        "lambdas, vectors = eigh(cov_matrix, eigvals=(0, 299))\n",
        "\n",
        "print(vectors.shape)\n",
        "\n",
        "vectors = vectors.T\n",
        "vectors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMNxH4gMB9IR",
        "outputId": "290fa68e-8a31-41fe-8054-3c9a80942b3f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 300)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aim: create a diagonal matrix -- so that we could maximize variance values\n",
        "# Choose a matrix P in which every row is an eigenvector of the covariance matrix.\n",
        "# This way we could create the diagonal matrix with P(X_T*X)\n",
        "\n",
        "new_coordinates_train = np.matmul(vectors, standardized_data.T).T\n",
        "\n",
        "new_coordinates_test = np.matmul(vectors, standardized_data_test.T).T"
      ],
      "metadata": {
        "id": "_9XiL6GzCTtq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_coordinates_train.shape, new_coordinates_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVr1hr9TC_i4",
        "outputId": "2104c179-987f-40ee-e7f4-0c9920e74c8c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 300), (10000, 300))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = new_coordinates_train\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_JjP_0fEjRh",
        "outputId": "9a99e044-edce-40aa-b1a8-d70a66b3dce0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 300) (60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = new_coordinates_test\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unoxeaiIEp2S",
        "outputId": "b4b852d6-4c92-43d2-9099-ee6795f68afd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 300) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nclasses = y_train.max() - y_train.min() + 1\n",
        "y_train = to_categorical(y_train, num_classes = nclasses)\n",
        "y_test = to_categorical(y_test, num_classes = nclasses)\n",
        "\n",
        "print(\"Shape of ytrain after encoding: \", y_train.shape)\n",
        "print(\"Shape of ytest after encoding: \", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvUnQqnHEwTN",
        "outputId": "2d1fa336-ba86-450c-9557-9eae4d2a4a87"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of ytrain after encoding:  (60000, 10)\n",
            "Shape of ytest after encoding:  (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build model"
      ],
      "metadata": {
        "id": "gCuwmeuMFEyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape = (X_train.shape[1],)))\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "mgjvMNdLFCsN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model"
      ],
      "metadata": {
        "id": "iWwpeo61GIHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='acc', patience=3)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "model.fit(X_train, y_train, epochs = 100, batch_size = 64, callbacks = callback, shuffle=True, validation_data = (X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_gYqkFgGG_S",
        "outputId": "2b91fe64-cd8d-4d36-f088-8d76c1464320"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 1.8688 - acc: 0.4234 - val_loss: 1.3661 - val_acc: 0.6053\n",
            "Epoch 2/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 1.1871 - acc: 0.6575 - val_loss: 1.0192 - val_acc: 0.7003\n",
            "Epoch 3/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.9120 - acc: 0.7347 - val_loss: 0.8775 - val_acc: 0.7383\n",
            "Epoch 4/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.7611 - acc: 0.7750 - val_loss: 0.7979 - val_acc: 0.7539\n",
            "Epoch 5/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.6684 - acc: 0.7992 - val_loss: 0.7676 - val_acc: 0.7659\n",
            "Epoch 6/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.6032 - acc: 0.8173 - val_loss: 0.7397 - val_acc: 0.7743\n",
            "Epoch 7/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.5553 - acc: 0.8309 - val_loss: 0.7237 - val_acc: 0.7812\n",
            "Epoch 8/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.5150 - acc: 0.8415 - val_loss: 0.7475 - val_acc: 0.7812\n",
            "Epoch 9/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.4832 - acc: 0.8519 - val_loss: 0.7406 - val_acc: 0.7847\n",
            "Epoch 10/100\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.4571 - acc: 0.8588 - val_loss: 0.7401 - val_acc: 0.7880\n",
            "Epoch 11/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.4329 - acc: 0.8669 - val_loss: 0.7398 - val_acc: 0.7898\n",
            "Epoch 12/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.4127 - acc: 0.8731 - val_loss: 0.7487 - val_acc: 0.7906\n",
            "Epoch 13/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.3948 - acc: 0.8778 - val_loss: 0.7569 - val_acc: 0.7869\n",
            "Epoch 14/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.3794 - acc: 0.8822 - val_loss: 0.7591 - val_acc: 0.7883\n",
            "Epoch 15/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.3651 - acc: 0.8862 - val_loss: 0.7670 - val_acc: 0.7877\n",
            "Epoch 16/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.3521 - acc: 0.8911 - val_loss: 0.7732 - val_acc: 0.7888\n",
            "Epoch 17/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.3390 - acc: 0.8964 - val_loss: 0.7923 - val_acc: 0.7887\n",
            "Epoch 18/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.3283 - acc: 0.8983 - val_loss: 0.8062 - val_acc: 0.7845\n",
            "Epoch 19/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.3181 - acc: 0.9011 - val_loss: 0.8141 - val_acc: 0.7877\n",
            "Epoch 20/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.3068 - acc: 0.9054 - val_loss: 0.8315 - val_acc: 0.7856\n",
            "Epoch 21/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.2984 - acc: 0.9085 - val_loss: 0.8404 - val_acc: 0.7876\n",
            "Epoch 22/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.2902 - acc: 0.9098 - val_loss: 0.8620 - val_acc: 0.7875\n",
            "Epoch 23/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.2814 - acc: 0.9124 - val_loss: 0.8880 - val_acc: 0.7847\n",
            "Epoch 24/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.2746 - acc: 0.9147 - val_loss: 0.9007 - val_acc: 0.7819\n",
            "Epoch 25/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.2668 - acc: 0.9171 - val_loss: 0.9354 - val_acc: 0.7810\n",
            "Epoch 26/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.2602 - acc: 0.9203 - val_loss: 0.9310 - val_acc: 0.7819\n",
            "Epoch 27/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.2526 - acc: 0.9217 - val_loss: 0.9598 - val_acc: 0.7807\n",
            "Epoch 28/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.2472 - acc: 0.9246 - val_loss: 0.9846 - val_acc: 0.7775\n",
            "Epoch 29/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.2409 - acc: 0.9255 - val_loss: 0.9969 - val_acc: 0.7802\n",
            "Epoch 30/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.2357 - acc: 0.9276 - val_loss: 1.0075 - val_acc: 0.7804\n",
            "Epoch 31/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.2288 - acc: 0.9304 - val_loss: 1.0209 - val_acc: 0.7780\n",
            "Epoch 32/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.2237 - acc: 0.9316 - val_loss: 1.0594 - val_acc: 0.7764\n",
            "Epoch 33/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.2191 - acc: 0.9331 - val_loss: 1.0624 - val_acc: 0.7764\n",
            "Epoch 34/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.2136 - acc: 0.9354 - val_loss: 1.0854 - val_acc: 0.7769\n",
            "Epoch 35/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.2087 - acc: 0.9366 - val_loss: 1.1109 - val_acc: 0.7756\n",
            "Epoch 36/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.2049 - acc: 0.9382 - val_loss: 1.1259 - val_acc: 0.7754\n",
            "Epoch 37/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.2009 - acc: 0.9388 - val_loss: 1.1411 - val_acc: 0.7748\n",
            "Epoch 38/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1964 - acc: 0.9413 - val_loss: 1.1610 - val_acc: 0.7744\n",
            "Epoch 39/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1929 - acc: 0.9427 - val_loss: 1.1738 - val_acc: 0.7776\n",
            "Epoch 40/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1899 - acc: 0.9431 - val_loss: 1.1935 - val_acc: 0.7741\n",
            "Epoch 41/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1839 - acc: 0.9455 - val_loss: 1.2327 - val_acc: 0.7736\n",
            "Epoch 42/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1806 - acc: 0.9463 - val_loss: 1.2494 - val_acc: 0.7734\n",
            "Epoch 43/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1775 - acc: 0.9465 - val_loss: 1.2685 - val_acc: 0.7710\n",
            "Epoch 44/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1738 - acc: 0.9484 - val_loss: 1.2901 - val_acc: 0.7694\n",
            "Epoch 45/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1698 - acc: 0.9496 - val_loss: 1.3001 - val_acc: 0.7693\n",
            "Epoch 46/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1672 - acc: 0.9511 - val_loss: 1.3308 - val_acc: 0.7698\n",
            "Epoch 47/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1633 - acc: 0.9522 - val_loss: 1.3535 - val_acc: 0.7668\n",
            "Epoch 48/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1598 - acc: 0.9526 - val_loss: 1.3612 - val_acc: 0.7676\n",
            "Epoch 49/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1576 - acc: 0.9540 - val_loss: 1.3919 - val_acc: 0.7643\n",
            "Epoch 50/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1537 - acc: 0.9558 - val_loss: 1.4015 - val_acc: 0.7662\n",
            "Epoch 51/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1514 - acc: 0.9563 - val_loss: 1.4187 - val_acc: 0.7676\n",
            "Epoch 52/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1484 - acc: 0.9579 - val_loss: 1.4284 - val_acc: 0.7660\n",
            "Epoch 53/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1454 - acc: 0.9579 - val_loss: 1.4691 - val_acc: 0.7634\n",
            "Epoch 54/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1432 - acc: 0.9583 - val_loss: 1.4818 - val_acc: 0.7633\n",
            "Epoch 55/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1404 - acc: 0.9599 - val_loss: 1.4834 - val_acc: 0.7650\n",
            "Epoch 56/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1372 - acc: 0.9601 - val_loss: 1.5284 - val_acc: 0.7622\n",
            "Epoch 57/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1355 - acc: 0.9616 - val_loss: 1.5438 - val_acc: 0.7624\n",
            "Epoch 58/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1330 - acc: 0.9622 - val_loss: 1.5849 - val_acc: 0.7628\n",
            "Epoch 59/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1321 - acc: 0.9627 - val_loss: 1.6039 - val_acc: 0.7588\n",
            "Epoch 60/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1285 - acc: 0.9643 - val_loss: 1.6155 - val_acc: 0.7626\n",
            "Epoch 61/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1254 - acc: 0.9647 - val_loss: 1.6141 - val_acc: 0.7623\n",
            "Epoch 62/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1231 - acc: 0.9661 - val_loss: 1.6260 - val_acc: 0.7627\n",
            "Epoch 63/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1209 - acc: 0.9665 - val_loss: 1.6691 - val_acc: 0.7615\n",
            "Epoch 64/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1192 - acc: 0.9672 - val_loss: 1.6812 - val_acc: 0.7614\n",
            "Epoch 65/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1165 - acc: 0.9688 - val_loss: 1.6969 - val_acc: 0.7615\n",
            "Epoch 66/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1158 - acc: 0.9679 - val_loss: 1.7366 - val_acc: 0.7613\n",
            "Epoch 67/100\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.1130 - acc: 0.9692 - val_loss: 1.7402 - val_acc: 0.7581\n",
            "Epoch 68/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1115 - acc: 0.9687 - val_loss: 1.8101 - val_acc: 0.7612\n",
            "Epoch 69/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1090 - acc: 0.9699 - val_loss: 1.8044 - val_acc: 0.7601\n",
            "Epoch 70/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1068 - acc: 0.9705 - val_loss: 1.8138 - val_acc: 0.7584\n",
            "Epoch 71/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1055 - acc: 0.9710 - val_loss: 1.8434 - val_acc: 0.7578\n",
            "Epoch 72/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1041 - acc: 0.9718 - val_loss: 1.8439 - val_acc: 0.7589\n",
            "Epoch 73/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1041 - acc: 0.9714 - val_loss: 1.8671 - val_acc: 0.7590\n",
            "Epoch 74/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.1002 - acc: 0.9737 - val_loss: 1.8789 - val_acc: 0.7597\n",
            "Epoch 75/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0982 - acc: 0.9736 - val_loss: 1.9300 - val_acc: 0.7578\n",
            "Epoch 76/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0962 - acc: 0.9744 - val_loss: 1.9414 - val_acc: 0.7564\n",
            "Epoch 77/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0956 - acc: 0.9755 - val_loss: 1.9529 - val_acc: 0.7585\n",
            "Epoch 78/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0929 - acc: 0.9765 - val_loss: 1.9950 - val_acc: 0.7574\n",
            "Epoch 79/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0909 - acc: 0.9767 - val_loss: 1.9982 - val_acc: 0.7551\n",
            "Epoch 80/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0903 - acc: 0.9766 - val_loss: 2.0115 - val_acc: 0.7552\n",
            "Epoch 81/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0883 - acc: 0.9771 - val_loss: 2.0458 - val_acc: 0.7553\n",
            "Epoch 82/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0870 - acc: 0.9777 - val_loss: 2.0683 - val_acc: 0.7557\n",
            "Epoch 83/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0863 - acc: 0.9778 - val_loss: 2.0631 - val_acc: 0.7560\n",
            "Epoch 84/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0850 - acc: 0.9792 - val_loss: 2.0835 - val_acc: 0.7551\n",
            "Epoch 85/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0823 - acc: 0.9798 - val_loss: 2.1006 - val_acc: 0.7543\n",
            "Epoch 86/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0803 - acc: 0.9805 - val_loss: 2.1449 - val_acc: 0.7530\n",
            "Epoch 87/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0798 - acc: 0.9801 - val_loss: 2.1616 - val_acc: 0.7556\n",
            "Epoch 88/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0786 - acc: 0.9804 - val_loss: 2.1772 - val_acc: 0.7554\n",
            "Epoch 89/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0778 - acc: 0.9805 - val_loss: 2.1919 - val_acc: 0.7538\n",
            "Epoch 90/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0754 - acc: 0.9811 - val_loss: 2.2116 - val_acc: 0.7538\n",
            "Epoch 91/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0740 - acc: 0.9819 - val_loss: 2.2349 - val_acc: 0.7556\n",
            "Epoch 92/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0734 - acc: 0.9823 - val_loss: 2.2569 - val_acc: 0.7523\n",
            "Epoch 93/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0719 - acc: 0.9833 - val_loss: 2.2956 - val_acc: 0.7528\n",
            "Epoch 94/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0707 - acc: 0.9830 - val_loss: 2.3230 - val_acc: 0.7503\n",
            "Epoch 95/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0689 - acc: 0.9838 - val_loss: 2.3424 - val_acc: 0.7510\n",
            "Epoch 96/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0691 - acc: 0.9835 - val_loss: 2.3855 - val_acc: 0.7538\n",
            "Epoch 97/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0668 - acc: 0.9846 - val_loss: 2.3992 - val_acc: 0.7514\n",
            "Epoch 98/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0661 - acc: 0.9846 - val_loss: 2.4072 - val_acc: 0.7498\n",
            "Epoch 99/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0643 - acc: 0.9853 - val_loss: 2.4411 - val_acc: 0.7510\n",
            "Epoch 100/100\n",
            "938/938 [==============================] - 1s 1ms/step - loss: 0.0648 - acc: 0.9845 - val_loss: 2.4389 - val_acc: 0.7515\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f796148f050>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use NN for classifying MNIST"
      ],
      "metadata": {
        "id": "w7o-yPkpNyKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "\n",
        "# Preoprocessing data\n",
        "train_X = train_X /255.\n",
        "test_X = test_X /255.\n",
        "\n",
        "# Categorical label\n",
        "nclasses = train_y.max() - train_y.min() + 1\n",
        "train_y = to_categorical(train_y, num_classes = nclasses)\n",
        "test_y = to_categorical(test_y, num_classes = nclasses)\n",
        "\n",
        "# Build model\n",
        "nn_model = Sequential()\n",
        "nn_model.add(Flatten(input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "nn_model.add(Dense(512, activation='relu'))\n",
        "nn_model.add(Dense(256, activation='relu'))\n",
        "nn_model.add(Dense(128, activation='relu'))\n",
        "nn_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Train model\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='acc', patience=3)\n",
        "nn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "nn_model.fit(train_X, train_y, epochs = 100, batch_size = 64, callbacks = callback, shuffle=True, validation_data = (test_X, test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBkCMWWCGaMb",
        "outputId": "6ab4c0d1-dd4e-4b7c-df6a-c2d5272c4bdc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.2037 - acc: 0.9406 - val_loss: 0.0961 - val_acc: 0.9689\n",
            "Epoch 2/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0828 - acc: 0.9743 - val_loss: 0.0831 - val_acc: 0.9754\n",
            "Epoch 3/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0571 - acc: 0.9819 - val_loss: 0.0799 - val_acc: 0.9755\n",
            "Epoch 4/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0434 - acc: 0.9858 - val_loss: 0.0717 - val_acc: 0.9799\n",
            "Epoch 5/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0351 - acc: 0.9889 - val_loss: 0.0822 - val_acc: 0.9771\n",
            "Epoch 6/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0290 - acc: 0.9906 - val_loss: 0.0828 - val_acc: 0.9777\n",
            "Epoch 7/100\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0263 - acc: 0.9917 - val_loss: 0.0770 - val_acc: 0.9813\n",
            "Epoch 8/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0204 - acc: 0.9935 - val_loss: 0.0754 - val_acc: 0.9804\n",
            "Epoch 9/100\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0197 - acc: 0.9934 - val_loss: 0.0963 - val_acc: 0.9781\n",
            "Epoch 10/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0191 - acc: 0.9941 - val_loss: 0.0917 - val_acc: 0.9788\n",
            "Epoch 11/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0152 - acc: 0.9950 - val_loss: 0.0705 - val_acc: 0.9830\n",
            "Epoch 12/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0141 - acc: 0.9955 - val_loss: 0.0890 - val_acc: 0.9796\n",
            "Epoch 13/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0149 - acc: 0.9952 - val_loss: 0.0927 - val_acc: 0.9807\n",
            "Epoch 14/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0122 - acc: 0.9963 - val_loss: 0.0865 - val_acc: 0.9805\n",
            "Epoch 15/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0115 - acc: 0.9966 - val_loss: 0.0974 - val_acc: 0.9778\n",
            "Epoch 16/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0131 - acc: 0.9958 - val_loss: 0.0922 - val_acc: 0.9805\n",
            "Epoch 17/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0117 - acc: 0.9963 - val_loss: 0.0925 - val_acc: 0.9809\n",
            "Epoch 18/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0122 - acc: 0.9967 - val_loss: 0.0873 - val_acc: 0.9818\n",
            "Epoch 19/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0076 - acc: 0.9975 - val_loss: 0.1130 - val_acc: 0.9811\n",
            "Epoch 20/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0100 - acc: 0.9970 - val_loss: 0.1063 - val_acc: 0.9791\n",
            "Epoch 21/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0075 - acc: 0.9977 - val_loss: 0.1044 - val_acc: 0.9790\n",
            "Epoch 22/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0117 - acc: 0.9963 - val_loss: 0.0971 - val_acc: 0.9807\n",
            "Epoch 23/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0042 - acc: 0.9988 - val_loss: 0.1146 - val_acc: 0.9806\n",
            "Epoch 24/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0099 - acc: 0.9973 - val_loss: 0.1064 - val_acc: 0.9810\n",
            "Epoch 25/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0076 - acc: 0.9979 - val_loss: 0.1071 - val_acc: 0.9811\n",
            "Epoch 26/100\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0081 - acc: 0.9978 - val_loss: 0.0840 - val_acc: 0.9849\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7962ceffd0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ablEPNhGOTC9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}